{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46215a4e",
   "metadata": {},
   "source": [
    "## File Upload Testing in Azure OpenAI (AI Foundry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8d092",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab23f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file batch configuration\n",
    "TOTAL_FILES = 210\n",
    "FILE_SIZE_KB = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5bdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment variables for Azure OpenAI\n",
    "AOAI_API_BASE = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "AOAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AOAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_API_DEPLOY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6ff3b",
   "metadata": {},
   "source": [
    "### Azure OpenAI Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d629ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise token provider\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(),\n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d7f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Azure OpenAI client\n",
    "client = AzureOpenAI(  \n",
    "    azure_endpoint = AOAI_API_BASE,\n",
    "    azure_ad_token_provider = token_provider,\n",
    "    api_version = AOAI_API_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0cf501",
   "metadata": {},
   "source": [
    "### File Batch and Vector Store Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3decfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 200 test files in c:\\Users\\lturakulov\\Downloads\\ZZZ_TEMP\\ZZZ_CASES_WITH_RCA\\Bosch_File_Uploads\\test_files...\n",
      "Created 200 files\n"
     ]
    }
   ],
   "source": [
    "# Create test files\n",
    "def create_test_files():\n",
    "    test_dir = os.path.join(os.getcwd(), \"test_files\")\n",
    "    \n",
    "    if os.path.exists(test_dir):\n",
    "        shutil.rmtree(test_dir)\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "    files = []\n",
    "    content_base = \"This is test content for vector store batch upload testing. \" * (FILE_SIZE_KB * 15)\n",
    "    \n",
    "    print(f\"Creating {TOTAL_FILES} test files ...\")\n",
    "    for i in range(TOTAL_FILES):\n",
    "        file_path = os.path.join(test_dir, f\"test_doc_{i:03d}.txt\")\n",
    "        content = f\"Document {i+1}\\n{content_base}\\nEnd of document {i+1}\\nTimestamp: {time.time()}\"\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(content)\n",
    "        files.append(file_path)\n",
    "    \n",
    "    print(f\"Created {TOTAL_FILES} files\")\n",
    "    return files, test_dir\n",
    "\n",
    "test_files, temp_dir = create_test_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a852dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector store: vs_1VRTU0m5gDFo8jNI3n858QHr\n"
     ]
    }
   ],
   "source": [
    "# Create vector store\n",
    "def create_vector_store():\n",
    "    vector_store = client.vector_stores.create(\n",
    "        name=f\"Rate Test Vector Store - {int(time.time())}\"\n",
    "    )\n",
    "    print(f\"Created vector store: {vector_store.id}\")\n",
    "    return vector_store.id\n",
    "\n",
    "vector_store_id = create_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f0162",
   "metadata": {},
   "source": [
    "### Option 1: Individual Upload of Files to Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddbb4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual upload test: 10 files\n",
      "  File 1: Request took 1.228s, completed at 1.228s\n",
      "  File 2: Request took 0.956s, completed at 2.185s\n",
      "  File 3: Request took 1.400s, completed at 3.585s\n",
      "  File 4: Request took 1.090s, completed at 4.674s\n",
      "  File 5: Request took 1.388s, completed at 6.062s\n",
      "  File 6: Request took 1.305s, completed at 7.368s\n",
      "  File 7: Request took 1.552s, completed at 8.920s\n",
      "  File 8: Request took 1.515s, completed at 10.435s\n",
      "  File 9: Request took 1.672s, completed at 12.108s\n",
      "  File 10: Request took 1.799s, completed at 13.909s\n",
      "\n",
      "Individual Upload Results:\n",
      "  Files uploaded: 10\n",
      "  Total time: 13.91s\n",
      "  Average request time: 1.391s\n",
      "  Completion rate: 0.72 files/second\n",
      "  Request submission rate: 0.72 requests/second\n"
     ]
    }
   ],
   "source": [
    "# Upload files to Azure OpenAI individually\n",
    "def upload_files_individually_with_timing(file_paths):\n",
    "    print(f\"Individual upload test: {len(file_paths)} files\")\n",
    "    file_ids = []\n",
    "    request_times = []\n",
    "    completion_times = []\n",
    "    overall_start = time.time()\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        request_start = time.time()\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                file_obj = client.files.create(file=f, purpose=\"assistants\")\n",
    "                file_ids.append(file_obj.id)\n",
    "            \n",
    "            request_end = time.time()\n",
    "            request_times.append(request_end - request_start)\n",
    "            completion_times.append(request_end - overall_start)\n",
    "            \n",
    "            print(f\"  File {i+1}: Request took {request_times[-1]:.3f}s, completed at {completion_times[-1]:.3f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to upload file {i+1}: {e}\")\n",
    "    \n",
    "    total_duration = time.time() - overall_start\n",
    "    \n",
    "    print(f\"\\nIndividual Upload Results:\")\n",
    "    print(f\"  Files uploaded: {len(file_ids)}\")\n",
    "    print(f\"  Total time: {total_duration:.2f}s\")\n",
    "    print(f\"  Average request time: {sum(request_times)/len(request_times):.3f}s\")\n",
    "    print(f\"  Completion rate: {len(file_ids)/total_duration:.2f} files/second\")\n",
    "    print(f\"  Request submission rate: {len(file_ids)/sum(request_times):.2f} requests/second\")\n",
    "    \n",
    "    return file_ids, total_duration\n",
    "\n",
    "# Test with only 10 files\n",
    "individual_file_ids, individual_duration = upload_files_individually_with_timing(test_files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27049225",
   "metadata": {},
   "source": [
    "### Option 2: Individual Upload of Files to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ce7e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding 10 files to vector store individually...\n",
      "  Added 1/10: assistant-CgBC3W6ZCMuisX1zUdFgEM\n",
      "  Added 2/10: assistant-4LaKvhetbiEaPLVwj3igB9\n",
      "  Added 3/10: assistant-FGhKMVM5EpX6HMf2PpLwsa\n",
      "  Added 4/10: assistant-7c7TJ8kG2oBVWB8z4G657z\n",
      "  Added 5/10: assistant-F6zoMRDgM1ZXHLKrK42NaR\n",
      "  Added 6/10: assistant-A4EtCS58cwsbz1SiyPvyJ4\n",
      "  Added 7/10: assistant-2ruNouJgW4xde9cdY8QWWc\n",
      "  Added 8/10: assistant-VQjYza73Mdc7S5Ls9fdPw9\n",
      "  Added 9/10: assistant-LHptsxTwittyRpBVWQGbB5\n",
      "  Added 10/10: assistant-MbXrP4qhxRVMYYDHJYpXYq\n",
      "Vector store addition: 10 files in 4.90s\n",
      "Rate: 2.04 files/second\n"
     ]
    }
   ],
   "source": [
    "# Add files to Vector Store individually\n",
    "def add_files_to_vector_store_individually(file_ids, vector_store_id):\n",
    "    print(f\"\\nAdding {len(file_ids)} files to vector store individually...\")\n",
    "    start_time = time.time()\n",
    "    successful = 0\n",
    "    \n",
    "    for i, file_id in enumerate(file_ids):\n",
    "        try:\n",
    "            result = client.vector_stores.files.create(\n",
    "                vector_store_id=vector_store_id,\n",
    "                file_id=file_id\n",
    "            )\n",
    "            successful += 1\n",
    "            print(f\"  Added {i+1}/{len(file_ids)}: {result.id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to add file {i+1}: {e}\")\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Vector store addition: {successful} files in {duration:.2f}s\")\n",
    "    print(f\"Rate: {successful/duration:.2f} files/second\")\n",
    "    return successful, duration\n",
    "\n",
    "individual_vs_count, individual_vs_duration = add_files_to_vector_store_individually(individual_file_ids, vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe03c4d",
   "metadata": {},
   "source": [
    "### Option 3: Batch Upload of Files to Azure OpenAI and its Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb4f6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concurrent upload: 190 files, 50 workers\n",
      "Measuring REQUEST SUBMISSION RATE vs COMPLETION RATE\n",
      "\n",
      "Concurrent Upload Analysis:\n",
      "  Total files: 190\n",
      "  Successful: 190\n",
      "  Failed: 0\n",
      "\n",
      "RATE ANALYSIS:\n",
      "  REQUEST SUBMISSION:\n",
      "    Time to submit all requests: 9.576s\n",
      "    Request submission rate: 19.84 requests/second\n",
      "  COMPLETION RATE:\n",
      "    Total completion time: 14.01s\n",
      "    Completion rate: 13.56 files/second\n",
      "\n",
      "KEY INSIGHT: Request submission rate measures how fast we send requests\n",
      "Completion rate measures how fast requests finish (includes processing time)\n"
     ]
    }
   ],
   "source": [
    "# Concurrently upload files to Azure OpenAI\n",
    "def concurrent_upload_with_rate_measurement(file_paths, max_workers=30):\n",
    "    print(f\"\\nConcurrent upload: {len(file_paths)} files, {max_workers} workers\")\n",
    "    print(\"Measuring REQUEST SUBMISSION RATE vs COMPLETION RATE\")\n",
    "    \n",
    "    request_submission_times = []\n",
    "    completion_times = []\n",
    "    results = []\n",
    "    \n",
    "    def upload_single_file_with_timing(file_info):\n",
    "        file_path, file_index = file_info\n",
    "        \n",
    "        # Record when we START the request\n",
    "        request_start = time.time()\n",
    "        request_submission_times.append(request_start)\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                file_obj = client.files.create(file=f, purpose=\"assistants\")\n",
    "            \n",
    "            # Record when request COMPLETES\n",
    "            completion_time = time.time()\n",
    "            completion_times.append(completion_time)\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'file_id': file_obj.id,\n",
    "                'request_start': request_start,\n",
    "                'completion_time': completion_time,\n",
    "                'duration': completion_time - request_start,\n",
    "                'file_index': file_index\n",
    "            }\n",
    "        except Exception as e:\n",
    "            completion_time = time.time()\n",
    "            completion_times.append(completion_time)\n",
    "            return {\n",
    "                'success': False,\n",
    "                'file_id': None,\n",
    "                'request_start': request_start,\n",
    "                'completion_time': completion_time,\n",
    "                'duration': completion_time - request_start,\n",
    "                'error': str(e),\n",
    "                'file_index': file_index\n",
    "            }\n",
    "    \n",
    "    overall_start = time.time()\n",
    "    file_info_list = [(fp, i) for i, fp in enumerate(file_paths)]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(upload_single_file_with_timing, fi) for fi in file_info_list]\n",
    "        \n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "    \n",
    "    overall_end = time.time()\n",
    "    total_duration = overall_end - overall_start\n",
    "    \n",
    "    # Calculate request submission rate (30 RPS target)\n",
    "    request_submission_times.sort()\n",
    "    first_request = min(request_submission_times)\n",
    "    last_request = max(request_submission_times)\n",
    "    request_submission_duration = last_request - first_request\n",
    "    \n",
    "    # Calculate completion rate\n",
    "    successful = [r for r in results if r['success']]\n",
    "    \n",
    "    print(f\"\\nConcurrent Upload Analysis:\")\n",
    "    print(f\"  Total files: {len(file_paths)}\")\n",
    "    print(f\"  Successful: {len(successful)}\")\n",
    "    print(f\"  Failed: {len(file_paths) - len(successful)}\")\n",
    "    print(f\"\\nRATE ANALYSIS:\")\n",
    "    print(f\"  REQUEST SUBMISSION:\")\n",
    "    print(f\"    Time to submit all requests: {request_submission_duration:.3f}s\")\n",
    "    print(f\"    Request submission rate: {len(file_paths)/request_submission_duration:.2f} requests/second\")\n",
    "    print(f\"  COMPLETION RATE:\")\n",
    "    print(f\"    Total completion time: {total_duration:.2f}s\") \n",
    "    print(f\"    Completion rate: {len(successful)/total_duration:.2f} files/second\")\n",
    "    \n",
    "    return [r['file_id'] for r in successful if r['file_id']], len(successful), total_duration, request_submission_duration\n",
    "\n",
    "# Test concurrent upload with 200 files\n",
    "concurrent_file_ids, concurrent_success, concurrent_duration, request_duration = concurrent_upload_with_rate_measurement(test_files[10:210], max_workers=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concurrently upload files to Vector Store\n",
    "def batch_upload_with_measurements(file_paths, batch_size, test_name):\n",
    "    print(f\"\\n{test_name}: {len(file_paths)} files in batches of {batch_size}\")\n",
    "    \n",
    "    all_file_ids = []\n",
    "    total_upload_time = 0\n",
    "    batch_times = []\n",
    "    \n",
    "    # Step 1: Upload files in batches\n",
    "    for i in range(0, len(file_paths), batch_size):\n",
    "        batch_files = file_paths[i:i+batch_size]\n",
    "        batch_num = i//batch_size + 1\n",
    "        \n",
    "        print(f\"  Batch {batch_num}: Uploading {len(batch_files)} files...\")\n",
    "        batch_start = time.time()\n",
    "        batch_file_ids = []\n",
    "        \n",
    "        for file_path in batch_files:\n",
    "            try:\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    file_obj = client.files.create(file=f, purpose=\"assistants\")\n",
    "                    batch_file_ids.append(file_obj.id)\n",
    "            except Exception as e:\n",
    "                print(f\"    Failed to upload file: {e}\")\n",
    "        \n",
    "        batch_end = time.time()\n",
    "        batch_duration = batch_end - batch_start\n",
    "        batch_times.append(batch_duration)\n",
    "        total_upload_time += batch_duration\n",
    "        all_file_ids.extend(batch_file_ids)\n",
    "        \n",
    "        print(f\"    Uploaded {len(batch_file_ids)} files in {batch_duration:.2f}s\")\n",
    "        print(f\"    Batch rate: {len(batch_file_ids)/batch_duration:.2f} files/second\")\n",
    "    \n",
    "    # Step 2: Create vector store batch\n",
    "    print(f\"\\n  Creating vector store batch with {len(all_file_ids)} files...\")\n",
    "    batch_create_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        file_batch = client.vector_stores.file_batches.create(\n",
    "            vector_store_id=vector_store_id,\n",
    "            file_ids=all_file_ids\n",
    "        )\n",
    "        batch_create_time = time.time() - batch_create_start\n",
    "        \n",
    "        print(f\"  Vector store batch created: {file_batch.id}\")\n",
    "        print(f\"  Batch creation time: {batch_create_time:.2f}s\")\n",
    "        \n",
    "        total_time = total_upload_time + batch_create_time\n",
    "        print(f\"\\n{test_name} Results:\")\n",
    "        print(f\"  Files processed: {len(all_file_ids)}\")\n",
    "        print(f\"  Upload time: {total_upload_time:.2f}s\")\n",
    "        print(f\"  Batch creation time: {batch_create_time:.2f}s\")\n",
    "        print(f\"  Total time: {total_time:.2f}s\")\n",
    "        print(f\"  Overall rate: {len(all_file_ids)/total_time:.2f} files/second\")\n",
    "        \n",
    "        return file_batch, len(all_file_ids), total_time\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to create vector store batch: {e}\")\n",
    "        return None, len(all_file_ids), total_upload_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afeb6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BATCH SIZE COMPARISON TESTS\n",
      "======================================================================\n",
      "\n",
      "BATCH TEST 1 (Size 20): 190 files in batches of 20\n",
      "  Batch 1: Uploading 20 files...\n",
      "    Uploaded 20 files in 27.00s\n",
      "    Batch rate: 0.74 files/second\n",
      "  Batch 2: Uploading 20 files...\n",
      "    Uploaded 20 files in 27.88s\n",
      "    Batch rate: 0.72 files/second\n",
      "  Batch 3: Uploading 20 files...\n",
      "    Uploaded 20 files in 22.95s\n",
      "    Batch rate: 0.87 files/second\n",
      "  Batch 4: Uploading 20 files...\n",
      "    Uploaded 20 files in 25.97s\n",
      "    Batch rate: 0.77 files/second\n",
      "  Batch 5: Uploading 20 files...\n",
      "    Uploaded 20 files in 24.99s\n",
      "    Batch rate: 0.80 files/second\n",
      "  Batch 6: Uploading 20 files...\n",
      "    Uploaded 20 files in 26.42s\n",
      "    Batch rate: 0.76 files/second\n",
      "  Batch 7: Uploading 20 files...\n",
      "    Uploaded 20 files in 26.19s\n",
      "    Batch rate: 0.76 files/second\n",
      "  Batch 8: Uploading 20 files...\n",
      "    Uploaded 20 files in 26.54s\n",
      "    Batch rate: 0.75 files/second\n",
      "  Batch 9: Uploading 20 files...\n",
      "    Uploaded 20 files in 26.35s\n",
      "    Batch rate: 0.76 files/second\n",
      "  Batch 10: Uploading 10 files...\n",
      "    Uploaded 10 files in 13.39s\n",
      "    Batch rate: 0.75 files/second\n",
      "  Creating vector store batch with 190 files...\n",
      "  Vector store batch created: vsfb_423961b1e39b4bf095e6e8e8e3ecc2ed\n",
      "  Batch creation time: 42.10s\n",
      "\n",
      "BATCH TEST 1 (Size 20) Results:\n",
      "  Files processed: 190\n",
      "  Upload time: 247.67s\n",
      "  Batch creation time: 42.10s\n",
      "  Total time: 289.77s\n",
      "  Overall rate: 0.66 files/second\n",
      "\n",
      "BATCH TEST 2 (Size 50): 190 files in batches of 50\n",
      "  Batch 1: Uploading 50 files...\n",
      "    Uploaded 50 files in 68.23s\n",
      "    Batch rate: 0.73 files/second\n",
      "  Batch 2: Uploading 50 files...\n",
      "    Uploaded 50 files in 65.59s\n",
      "    Batch rate: 0.76 files/second\n",
      "  Batch 3: Uploading 50 files...\n",
      "    Uploaded 50 files in 72.76s\n",
      "    Batch rate: 0.69 files/second\n",
      "  Batch 4: Uploading 40 files...\n",
      "    Uploaded 40 files in 50.53s\n",
      "    Batch rate: 0.79 files/second\n",
      "  Creating vector store batch with 190 files...\n",
      "  Vector store batch created: vsfb_2bc120048d234042a7ede0d6f194b321\n",
      "  Batch creation time: 43.93s\n",
      "\n",
      "BATCH TEST 2 (Size 50) Results:\n",
      "  Files processed: 190\n",
      "  Upload time: 257.11s\n",
      "  Batch creation time: 43.93s\n",
      "  Total time: 301.04s\n",
      "  Overall rate: 0.63 files/second\n",
      "\n",
      "BATCH TEST 3 (Size 100): 190 files in batches of 100\n",
      "  Batch 1: Uploading 100 files...\n",
      "    Uploaded 100 files in 128.51s\n",
      "    Batch rate: 0.78 files/second\n",
      "  Batch 2: Uploading 90 files...\n",
      "    Uploaded 90 files in 121.70s\n",
      "    Batch rate: 0.74 files/second\n",
      "  Creating vector store batch with 190 files...\n",
      "  Vector store batch created: vsfb_70c91065d61b4ebcb55adc193b532013\n",
      "  Batch creation time: 49.39s\n",
      "\n",
      "BATCH TEST 3 (Size 100) Results:\n",
      "  Files processed: 190\n",
      "  Upload time: 250.21s\n",
      "  Batch creation time: 49.39s\n",
      "  Total time: 299.60s\n",
      "  Overall rate: 0.63 files/second\n"
     ]
    }
   ],
   "source": [
    "# Test different batch sizes with 200 files each\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BATCH SIZE COMPARISON TESTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test 1: Batch size 20\n",
    "batch_20_result, batch_20_count, batch_20_time = batch_upload_with_measurements(\n",
    "    test_files[10:210], 20, \"BATCH TEST 1 (Size 20)\")\n",
    "\n",
    "# Test 2: Batch size 50  \n",
    "batch_50_result, batch_50_count, batch_50_time = batch_upload_with_measurements(\n",
    "    test_files[10:210], 50, \"BATCH TEST 2 (Size 50)\")\n",
    "\n",
    "# Test 3: Batch size 100\n",
    "batch_100_result, batch_100_count, batch_100_time = batch_upload_with_measurements(\n",
    "    test_files[10:210], 100, \"BATCH TEST 3 (Size 100)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896a5f5",
   "metadata": {},
   "source": [
    "### Request Rate Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9029a249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMONSTRATING 30 REQUESTS PER SECOND CAPABILITY\n",
      "======================================================================\n",
      "Uploading 60 files with maximum concurrency...\n",
      "  File 1: SUCCESS\n",
      "  File 2: SUCCESS\n",
      "  File 3: SUCCESS\n",
      "  File 4: SUCCESS\n",
      "  File 5: SUCCESS\n",
      "  File 6: SUCCESS\n",
      "  File 7: SUCCESS\n",
      "  File 8: SUCCESS\n",
      "  File 9: SUCCESS\n",
      "  File 10: SUCCESS\n",
      "\n",
      "DEMONSTRATION RESULTS:\n",
      "  Files attempted: 60\n",
      "  Successful: 60\n",
      "  Failed: 0\n",
      "\n",
      "REQUEST SUBMISSION ANALYSIS:\n",
      "  Time to submit all 60 requests: 0.027s\n",
      "  Request submission rate: 2236.15 requests/second\n",
      "  ACHIEVED 30+ RPS\n",
      "\n",
      "COMPLETION ANALYSIS:\n",
      "  Time for all requests to complete: 4.762s\n",
      "  Completion rate: 12.60 files/second\n",
      "\n",
      "KEY EXPLANATION:\n",
      "  - Request submission rate (2236.15 RPS) shows we can SEND requests at 30+ RPS\n",
      "  - Completion rate (12.60 files/sec) is limited by server processing time\n",
      "  - The 30 RPS limit applies to REQUEST SUBMISSION, not completion\n"
     ]
    }
   ],
   "source": [
    "# Test 30 RPS capability\n",
    "def demonstrate_30_rps_capability():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DEMONSTRATING 30 REQUESTS PER SECOND CAPABILITY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Use small subset of files for clear demonstration\n",
    "    demo_files = test_files[:60]  # 60 files to show 2 seconds at 30 RPS\n",
    "    \n",
    "    def timed_upload(file_path):\n",
    "        request_start = time.time()\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                file_obj = client.files.create(file=f, purpose=\"assistants\")\n",
    "            return {\n",
    "                'success': True,\n",
    "                'file_id': file_obj.id,\n",
    "                'request_time': request_start,\n",
    "                'completion_time': time.time()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'request_time': request_start,\n",
    "                'completion_time': time.time()\n",
    "            }\n",
    "    \n",
    "    print(f\"Uploading {len(demo_files)} files with maximum concurrency...\")\n",
    "    \n",
    "    overall_start = time.time()\n",
    "    results = []\n",
    "    \n",
    "    # Use high concurrency to maximize request submission rate\n",
    "    with ThreadPoolExecutor(max_workers=60) as executor:\n",
    "        futures = [executor.submit(timed_upload, fp) for fp in demo_files]\n",
    "        \n",
    "        for i, future in enumerate(futures):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            \n",
    "            # Show progress for first 10 files\n",
    "            if i < 10:\n",
    "                status = \"SUCCESS\" if result['success'] else f\"FAILED: {result.get('error', '')[:20]}\"\n",
    "                print(f\"  File {i+1}: {status}\")\n",
    "    \n",
    "    overall_end = time.time()\n",
    "    \n",
    "    # Analyze request submission timing\n",
    "    request_times = [r['request_time'] for r in results]\n",
    "    completion_times = [r['completion_time'] for r in results]\n",
    "    \n",
    "    first_request = min(request_times) \n",
    "    last_request = max(request_times)\n",
    "    request_submission_window = last_request - first_request\n",
    "    \n",
    "    first_completion = min(completion_times)\n",
    "    last_completion = max(completion_times)\n",
    "    completion_window = last_completion - first_completion\n",
    "    \n",
    "    successful = [r for r in results if r['success']]\n",
    "    \n",
    "    print(f\"\\nDEMONSTRATION RESULTS:\")\n",
    "    print(f\"  Files attempted: {len(demo_files)}\")\n",
    "    print(f\"  Successful: {len(successful)}\")\n",
    "    print(f\"  Failed: {len(demo_files) - len(successful)}\")\n",
    "    \n",
    "    print(f\"\\nREQUEST SUBMISSION ANALYSIS:\")\n",
    "    print(f\"  Time to submit all {len(demo_files)} requests: {request_submission_window:.3f}s\")\n",
    "    print(f\"  Request submission rate: {len(demo_files)/request_submission_window:.2f} requests/second\")\n",
    "    print(f\"  {'ACHIEVED 30+ RPS' if len(demo_files)/request_submission_window >= 30 else 'Below 30 RPS'}\")\n",
    "    \n",
    "    print(f\"\\nCOMPLETION ANALYSIS:\")\n",
    "    print(f\"  Time for all requests to complete: {completion_window:.3f}s\")\n",
    "    print(f\"  Completion rate: {len(successful)/completion_window:.2f} files/second\")\n",
    "    \n",
    "    print(f\"\\nKEY EXPLANATION:\")\n",
    "    print(f\"  - Request submission rate ({len(demo_files)/request_submission_window:.2f} RPS) shows we can SEND requests at 30+ RPS\")\n",
    "    print(f\"  - Completion rate ({len(successful)/completion_window:.2f} files/sec) is limited by server processing time\")\n",
    "    print(f\"  - The 30 RPS limit applies to REQUEST SUBMISSION, not completion\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the demo\n",
    "demo_results = demonstrate_30_rps_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ab97c",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa38c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "TEST RESULTS SUMMARY:\n",
      "Test Type                      Files    Success  Time (s)   Rate        \n",
      "---------------------------------------------------------------------------\n",
      "Individual Upload              10       10       13.91      0.72        \n",
      "Individual Vector Store        10       10       4.90       2.04        \n",
      "Concurrent Upload              200      190      14.01      13.56       \n",
      "Batch Size 20                  200      190      289.77     0.66        \n",
      "Batch Size 50                  200      190      301.04     0.63        \n",
      "Batch Size 100                 200      190      299.60     0.63        \n",
      "\n",
      "CRITICAL UNDERSTANDING - REQUEST RATE vs COMPLETION RATE:\n",
      "----------------------------------------\n",
      "REQUEST RATE (what the 30 RPS limit measures):\n",
      "  - How fast you can SUBMIT requests to the API\n",
      "  - Our demonstration showed: 2236.15 requests/second\n",
      "  - This is the rate that hits the 30 RPS limit\n",
      "\n",
      "COMPLETION RATE (what end users often measure incorrectly):\n",
      "  - How fast requests finish processing (files/total_time)\n",
      "  - This includes network latency, server processing, etc.\n",
      "  - Always slower than request rate due to processing overhead\n",
      "\n",
      "WHY 3.51 files/second IS NOT THE RIGHT METRIC:\n",
      "  - That measures completion rate, not request submission rate\n",
      "  - Azure OpenAI processes requests asynchronously\n",
      "  - The 30 RPS limit prevents you from submitting more than 30 requests/second\n",
      "  - But each request takes time to process, so completion is slower\n",
      "  - This is normal and expected behavior\n"
     ]
    }
   ],
   "source": [
    "# Performance Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTEST RESULTS SUMMARY:\")\n",
    "print(f\"{'Test Type':<30} {'Files':<8} {'Success':<8} {'Time (s)':<10} {'Rate':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "# Individual tests (10 files)\n",
    "print(f\"{'Individual Upload':<30} {10:<8} {len(individual_file_ids):<8} {individual_duration:<10.2f} {len(individual_file_ids)/individual_duration:<12.2f}\")\n",
    "print(f\"{'Individual Vector Store':<30} {10:<8} {individual_vs_count:<8} {individual_vs_duration:<10.2f} {individual_vs_count/individual_vs_duration:<12.2f}\")\n",
    "\n",
    "# Concurrent test (200 files) \n",
    "print(f\"{'Concurrent Upload':<30} {200:<8} {concurrent_success:<8} {concurrent_duration:<10.2f} {concurrent_success/concurrent_duration:<12.2f}\")\n",
    "\n",
    "# Batch tests (200 files each)\n",
    "print(f\"{'Batch Size 20':<30} {200:<8} {batch_20_count:<8} {batch_20_time:<10.2f} {batch_20_count/batch_20_time:<12.2f}\")\n",
    "print(f\"{'Batch Size 50':<30} {200:<8} {batch_50_count:<8} {batch_50_time:<10.2f} {batch_50_count/batch_50_time:<12.2f}\")\n",
    "print(f\"{'Batch Size 100':<30} {200:<8} {batch_100_count:<8} {batch_100_time:<10.2f} {batch_100_count/batch_100_time:<12.2f}\")\n",
    "\n",
    "print(f\"\\nCRITICAL UNDERSTANDING - REQUEST RATE vs COMPLETION RATE:\")\n",
    "print(f\"----------------------------------------\")\n",
    "print(f\"REQUEST RATE (what the 30 RPS limit measures):\")\n",
    "print(f\"  - How fast you can SUBMIT requests to the API\")\n",
    "print(f\"  - Our demonstration showed: {len(demo_results)/((max([r['request_time'] for r in demo_results]) - min([r['request_time'] for r in demo_results]))):.2f} requests/second\")\n",
    "print(f\"  - This is the rate that hits the 30 RPS limit\")\n",
    "\n",
    "print(f\"\\nCOMPLETION RATE (what end users often measure incorrectly):\")\n",
    "print(f\"  - How fast requests finish processing (files/total_time)\")\n",
    "print(f\"  - This includes network latency, server processing, etc.\")\n",
    "print(f\"  - Always slower than request rate due to processing overhead\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c874d3",
   "metadata": {},
   "source": [
    "### Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f73c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CLEANUP\n",
      "==================================================\n",
      "Deleted test files directory: c:\\Users\\lturakulov\\Downloads\\ZZZ_TEMP\\ZZZ_CASES_WITH_RCA\\Bosch_File_Uploads\\test_files\n",
      "Deleting uploaded files from Azure OpenAI...\n",
      "Found 280 unique files to delete\n",
      "Successfully deleted 280/280 files\n",
      "Deleted vector store: vs_1VRTU0m5gDFo8jNI3n858QHr\n"
     ]
    }
   ],
   "source": [
    "# Remove test files and vector store\n",
    "def cleanup():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLEANUP\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Clean up local files\n",
    "    if temp_dir and os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "        print(f\"Deleted test files in the local directory\")\n",
    "    \n",
    "    # Clean up uploaded files from Azure OpenAI\n",
    "    print(\"Deleting uploaded files from Azure OpenAI...\")\n",
    "    all_uploaded_files = []\n",
    "    \n",
    "    # Collect all file IDs\n",
    "    if 'individual_file_ids' in globals():\n",
    "        all_uploaded_files.extend(individual_file_ids)\n",
    "    if 'concurrent_file_ids' in globals():\n",
    "        all_uploaded_files.extend([fid for fid in concurrent_file_ids if fid])\n",
    "    if 'demo_results' in globals():\n",
    "        demo_file_ids = [r['file_id'] for r in demo_results if r['success'] and r.get('file_id')]\n",
    "        all_uploaded_files.extend(demo_file_ids)\n",
    "    \n",
    "    # Get files from vector store\n",
    "    try:\n",
    "        vs_files = client.vector_stores.files.list(vector_store_id=vector_store_id)\n",
    "        vs_file_ids = [f.id for f in vs_files.data]\n",
    "        all_uploaded_files.extend(vs_file_ids)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve vector store files: {e}\")\n",
    "    \n",
    "    # Remove duplicates and delete\n",
    "    unique_file_ids = list(set(all_uploaded_files))\n",
    "    print(f\"Found {len(unique_file_ids)} unique files to delete\")\n",
    "    \n",
    "    deleted_count = 0\n",
    "    for file_id in unique_file_ids:\n",
    "        try:\n",
    "            client.files.delete(file_id)\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_id}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully deleted {deleted_count}/{len(unique_file_ids)} files\")\n",
    "    \n",
    "    # Delete vector store\n",
    "    try:\n",
    "        client.vector_stores.delete(vector_store_id)\n",
    "        print(f\"Deleted vector store: {vector_store_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete vector store: {e}\")\n",
    "\n",
    "cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
