{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46215a4e",
   "metadata": {},
   "source": [
    "## File Upload Testing in Azure OpenAI (AI Foundry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8d092",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab23f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512b7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file batch configuration\n",
    "TOTAL_FILES = 200\n",
    "FILE_SIZE_KB = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5bdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment variables for Azure OpenAI\n",
    "AOAI_API_BASE = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "AOAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AOAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_API_DEPLOY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6ff3b",
   "metadata": {},
   "source": [
    "### Azure OpenAI Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d629ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise token provider\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(),\n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d7f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Azure OpenAI client\n",
    "client = AzureOpenAI(  \n",
    "    azure_endpoint = AOAI_API_BASE,\n",
    "    azure_ad_token_provider = token_provider,\n",
    "    api_version = AOAI_API_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0cf501",
   "metadata": {},
   "source": [
    "### File Batch and Vector Store Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3decfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 200 test files ...\n",
      "Created 200 files\n"
     ]
    }
   ],
   "source": [
    "# Create test files\n",
    "def create_test_files():\n",
    "    test_dir = os.path.join(os.getcwd(), \"test_files\")\n",
    "    \n",
    "    if os.path.exists(test_dir):\n",
    "        shutil.rmtree(test_dir)\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "    files = []\n",
    "    content_base = \"This is test content for vector store batch upload testing. \" * (FILE_SIZE_KB * 15)\n",
    "    \n",
    "    print(f\"Creating {TOTAL_FILES} test files ...\")\n",
    "    for i in range(TOTAL_FILES):\n",
    "        file_path = os.path.join(test_dir, f\"test_doc_{i:03d}.txt\")\n",
    "        content = f\"Document {i+1}\\n{content_base}\\nEnd of document {i+1}\\nTimestamp: {time.time()}\"\n",
    "        \n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(content)\n",
    "        files.append(file_path)\n",
    "    \n",
    "    print(f\"Created {TOTAL_FILES} files\")\n",
    "    return files, test_dir\n",
    "\n",
    "test_files, temp_dir = create_test_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a852dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector store: vs_vSoLHyPUBKcUNS20sLjXOfEK\n"
     ]
    }
   ],
   "source": [
    "# Create vector store\n",
    "def create_vector_store():\n",
    "    vector_store = client.vector_stores.create(\n",
    "        name=f\"Rate Test Vector Store - {int(time.time())}\"\n",
    "    )\n",
    "    print(f\"Created vector store: {vector_store.id}\")\n",
    "    return vector_store.id\n",
    "\n",
    "vector_store_id = create_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f0162",
   "metadata": {},
   "source": [
    "### Option 1: Individual Sequential Test (10 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddbb4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Running Individual Sequential Test: 10 files\n",
      "======================================================================\n",
      "  Processed file 1/10\n",
      "  Processed file 2/10\n",
      "  Processed file 3/10\n",
      "  Processed file 4/10\n",
      "  Processed file 5/10\n",
      "  Processed file 6/10\n",
      "  Processed file 7/10\n",
      "  Processed file 8/10\n",
      "  Processed file 9/10\n",
      "  Processed file 10/10\n",
      "\n",
      "--- Individual Test Results ---\n",
      "{\n",
      "  \"Test Scenario\": \"1. Individual Sequential\",\n",
      "  \"Files\": 10,\n",
      "  \"Workers\": 1,\n",
      "  \"Successful\": 10,\n",
      "  \"Submission Rate (RPS)\": \"0.56\",\n",
      "  \"Completion Rate (files/sec)\": \"0.56\",\n",
      "  \"Total Time (s)\": \"17.70\",\n",
      "  \"Rate Limit Errors\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Helper function to run individual sequential test\n",
    "def run_individual_sequential_test(file_paths, vector_store_id):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Running Individual Sequential Test: {len(file_paths)} files\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    successful_uploads = 0\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        try:\n",
    "            # Step 1: Upload from local disk\n",
    "            with open(file_path, 'rb') as f:\n",
    "                uploaded_file = client.files.create(file=f, purpose=\"assistants\")\n",
    "            \n",
    "            # Step 2: Add to vector store\n",
    "            client.vector_stores.files.create(\n",
    "                vector_store_id=vector_store_id,\n",
    "                file_id=uploaded_file.id\n",
    "            )\n",
    "            successful_uploads += 1\n",
    "            print(f\"  Processed file {i+1}/{len(file_paths)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Failed to process file {i+1}: {e}\")\n",
    "            \n",
    "    total_duration = time.time() - start_time\n",
    "    completion_rate = successful_uploads / total_duration if total_duration > 0 else 0\n",
    "    \n",
    "    print(\"\\n--- Individual Test Results ---\")\n",
    "    return {\n",
    "        \"Test Scenario\": \"1. Individual Sequential\",\n",
    "        \"Files\": len(file_paths),\n",
    "        \"Workers\": 1,\n",
    "        \"Successful\": successful_uploads,\n",
    "        \"Submission Rate (RPS)\": f\"{completion_rate:.2f}\",\n",
    "        \"Completion Rate (files/sec)\": f\"{completion_rate:.2f}\",\n",
    "        \"Total Time (s)\": f\"{total_duration:.2f}\",\n",
    "        \"Rate Limit Errors\": 0\n",
    "    }\n",
    "\n",
    "# Run the individual test on the first 10 files\n",
    "individual_test_results = run_individual_sequential_test(test_files[:10], vector_store_id)\n",
    "print(json.dumps(individual_test_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27049225",
   "metadata": {},
   "source": [
    "### Option 2: Individual Upload of Files to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb4f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run unified concurrent test\n",
    "def run_unified_concurrent_test(file_paths, vector_store_id, num_workers):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Running Unified Concurrent Test: {len(file_paths)} files with {num_workers} workers\")\n",
    "    print(f\"Target Vector Store: {vector_store_id}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # The task for each thread. This represents one complete, realistic operation.\n",
    "    def upload_and_add_worker(file_path):\n",
    "        request_start_time = time.time()\n",
    "        try:\n",
    "            # Step 1: Upload the file from the local machine.\n",
    "            with open(file_path, 'rb') as f:\n",
    "                uploaded_file = client.files.create(file=f, purpose=\"assistants\")\n",
    "            \n",
    "            # Step 2: Add the now-uploaded file to the vector store.\n",
    "            client.vector_stores.files.create(\n",
    "                vector_store_id=vector_store_id,\n",
    "                file_id=uploaded_file.id\n",
    "            )\n",
    "            return {'success': True, 'request_time': request_start_time, 'completion_time': time.time(), 'error': None}\n",
    "        except Exception as e:\n",
    "            return {'success': False, 'request_time': request_start_time, 'completion_time': time.time(), 'error': str(e)}\n",
    "\n",
    "    # Use ThreadPoolExecutor to run the complete workflow concurrently\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(upload_and_add_worker, fp) for fp in file_paths]\n",
    "        for i, future in enumerate(futures):\n",
    "            results.append(future.result())\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  ... {i+1}/{len(file_paths)} tasks completed.\")\n",
    "\n",
    "    # --- Analyze the results ---\n",
    "    request_times = [r['request_time'] for r in results]\n",
    "    completion_times = [r['completion_time'] for r in results]\n",
    "    successful_results = [r for r in results if r['success']]\n",
    "    \n",
    "    submission_window = max(request_times) - min(request_times)\n",
    "    submission_rate = len(file_paths) / submission_window if submission_window > 0 else float('inf')\n",
    "    \n",
    "    total_duration = max(completion_times) - min(request_times)\n",
    "    completion_rate = len(successful_results) / total_duration if total_duration > 0 else 0\n",
    "    \n",
    "    rate_limit_errors = sum(1 for r in results if not r['success'] and '429' in r['error'])\n",
    "\n",
    "    return {\n",
    "        \"Test Scenario\": f\"2. Concurrent ({num_workers} Workers)\",\n",
    "        \"Files\": len(file_paths),\n",
    "        \"Workers\": num_workers,\n",
    "        \"Successful\": len(successful_results),\n",
    "        \"Submission Rate (RPS)\": f\"{submission_rate:.2f}\",\n",
    "        \"Completion Rate (files/sec)\": f\"{completion_rate:.2f}\",\n",
    "        \"Total Time (s)\": f\"{total_duration:.2f}\",\n",
    "        \"Rate Limit Errors\": rate_limit_errors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afeb6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Running Unified Concurrent Test: 200 files with 20 workers\n",
      "Target Vector Store: vs_vSoLHyPUBKcUNS20sLjXOfEK\n",
      "======================================================================\n",
      "  ... 20/200 tasks completed.\n",
      "  ... 40/200 tasks completed.\n",
      "  ... 60/200 tasks completed.\n",
      "  ... 80/200 tasks completed.\n",
      "  ... 100/200 tasks completed.\n",
      "  ... 120/200 tasks completed.\n",
      "  ... 140/200 tasks completed.\n",
      "  ... 160/200 tasks completed.\n",
      "  ... 180/200 tasks completed.\n",
      "  ... 200/200 tasks completed.\n",
      "\n",
      "======================================================================\n",
      "Running Unified Concurrent Test: 200 files with 50 workers\n",
      "Target Vector Store: vs_vSoLHyPUBKcUNS20sLjXOfEK\n",
      "======================================================================\n",
      "  ... 20/200 tasks completed.\n",
      "  ... 40/200 tasks completed.\n",
      "  ... 60/200 tasks completed.\n",
      "  ... 80/200 tasks completed.\n",
      "  ... 100/200 tasks completed.\n",
      "  ... 120/200 tasks completed.\n",
      "  ... 140/200 tasks completed.\n",
      "  ... 160/200 tasks completed.\n",
      "  ... 180/200 tasks completed.\n",
      "  ... 200/200 tasks completed.\n",
      "\n",
      "======================================================================\n",
      "Running Unified Concurrent Test: 200 files with 100 workers\n",
      "Target Vector Store: vs_vSoLHyPUBKcUNS20sLjXOfEK\n",
      "======================================================================\n",
      "  ... 20/200 tasks completed.\n",
      "  ... 40/200 tasks completed.\n",
      "  ... 60/200 tasks completed.\n",
      "  ... 80/200 tasks completed.\n",
      "  ... 100/200 tasks completed.\n",
      "  ... 120/200 tasks completed.\n",
      "  ... 140/200 tasks completed.\n",
      "  ... 160/200 tasks completed.\n",
      "  ... 180/200 tasks completed.\n",
      "  ... 200/200 tasks completed.\n"
     ]
    }
   ],
   "source": [
    "# Test different batch sizes with 200 files each\n",
    "scenarios_to_run = [20, 50, 100]\n",
    "all_concurrent_results = []\n",
    "for worker_count in scenarios_to_run:\n",
    "    # **# BOLD: Call the test function, passing the main_vector_store_id.**\n",
    "    test_result = run_unified_concurrent_test(\n",
    "        file_paths=test_files,\n",
    "        vector_store_id=vector_store_id,\n",
    "        num_workers=worker_count\n",
    "    )\n",
    "    all_concurrent_results.append(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ab97c",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2aa38c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================================================================================================\n",
      "PERFORMANCE ANALYSIS OF UNIFIED UPLOAD WORKFLOW\n",
      "==============================================================================================================\n",
      "              Test Scenario  Files  Workers  Successful Submission Rate (RPS) Completion Rate (files/sec) Total Time (s)  Rate Limit Errors\n",
      "   1. Individual Sequential     10        1          10                  0.56                        0.56          17.70                  0\n",
      " 2. Concurrent (20 Workers)    200       20         200                  8.78                        7.88          25.37                  0\n",
      " 2. Concurrent (50 Workers)    200       50         200                 15.42                       10.49          19.06                  0\n",
      "2. Concurrent (100 Workers)    200      100         199                 19.47                        9.44          21.08                  1\n",
      "==============================================================================================================\n",
      "\n",
      "This summary reflects the performance of the complete, realistic workflow: uploading a file from your machine directly into a vector store.\n",
      "\n",
      "1. REQUEST SUBMISSION RATE (The '30 RPS' Limit):\n",
      "   - This measures how fast we can INITIATE the complete upload process.\n",
      "   - As you increase the number of 'Workers' (concurrent threads), this rate increases significantly.\n",
      "\n",
      "2. COMPLETION RATE (End-to-End Throughput):\n",
      "   - This measures how fast the entire process FINISHES for each file.\n",
      "   - This rate is naturally lower, because of the time required to ingest and index the files.\n",
      "   - The server processes the queue asynchronously, so completion will always lag behind submission.\n"
     ]
    }
   ],
   "source": [
    "# Performance Summary\n",
    "final_results = [individual_test_results] + all_concurrent_results\n",
    "summary_df = pd.DataFrame(final_results)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*110)\n",
    "print(\"PERFORMANCE ANALYSIS OF UNIFIED UPLOAD WORKFLOW\")\n",
    "print(\"=\"*110)\n",
    "# Reorder columns for clarity\n",
    "summary_df = summary_df[[\n",
    "    \"Test Scenario\", \"Files\", \"Workers\", \"Successful\", \"Submission Rate (RPS)\", \n",
    "    \"Completion Rate (files/sec)\", \"Total Time (s)\", \"Rate Limit Errors\"\n",
    "]]\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*110)\n",
    "\n",
    "print(\"\\nThis summary reflects the performance of the complete, realistic workflow: uploading a file from your machine directly into a vector store.\")\n",
    "\n",
    "print(\"\\n1. REQUEST SUBMISSION RATE (The '30 RPS' Limit):\")\n",
    "print(\"   - This measures how fast we can INITIATE the complete upload process.\")\n",
    "print(\"   - As you increase the number of 'Workers' (concurrent threads), this rate increases significantly.\")\n",
    "\n",
    "print(\"\\n2. COMPLETION RATE (End-to-End Throughput):\")\n",
    "print(\"   - This measures how fast the entire process FINISHES for each file.\")\n",
    "print(\"   - This rate is naturally lower, because of the time required to ingest and index the files.\")\n",
    "print(\"   - The server processes the queue asynchronously, so completion will always lag behind submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c874d3",
   "metadata": {},
   "source": [
    "### Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f73c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CLEANUP\n",
      "==================================================\n",
      "Deleted test files in the local directory\n",
      "Deleting main vector store and all uploaded files from Azure OpenAI...\n",
      "Found 609 total files in the account to delete...\n",
      "Successfully deleted 609/609 files.\n",
      "Deleted vector store: vs_vSoLHyPUBKcUNS20sLjXOfEK\n"
     ]
    }
   ],
   "source": [
    "# Remove test files and vector store\n",
    "def cleanup():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLEANUP\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Clean up local files\n",
    "    if 'temp_dir' in globals() and temp_dir and os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "        print(f\"Deleted test files in the local directory\")\n",
    "    \n",
    "    # Clean up the vector store and any remaining files.\n",
    "    print(\"Deleting main vector store and all uploaded files from Azure OpenAI...\")\n",
    "    \n",
    "    all_uploaded_files = client.files.list()\n",
    "    file_ids_to_delete = [f.id for f in all_uploaded_files]\n",
    "    \n",
    "    deleted_count = 0\n",
    "    print(f\"Found {len(file_ids_to_delete)} total files in the account to delete...\")\n",
    "    for file_id in file_ids_to_delete:\n",
    "        try:\n",
    "            client.files.delete(file_id)\n",
    "            deleted_count += 1\n",
    "        except Exception:\n",
    "            # Ignore errors for files that might already be deleted\n",
    "            pass\n",
    "    print(f\"Successfully deleted {deleted_count}/{len(file_ids_to_delete)} files.\")\n",
    "    \n",
    "    # Delete the main vector store\n",
    "    try:\n",
    "        client.vector_stores.delete(vector_store_id=vector_store_id)\n",
    "        print(f\"Deleted vector store: {vector_store_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete vector store {vector_store_id}: {e}\")\n",
    "\n",
    "cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
